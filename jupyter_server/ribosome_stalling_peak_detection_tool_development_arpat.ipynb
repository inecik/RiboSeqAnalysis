{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ribosome Stalling Sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create the infrastructre for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "sys.path.insert(0, '/home/raf_pc/Kemal/RiboSeqAnalysis')\n",
    "from infrastructure.main import *\n",
    "\n",
    "temp_repo_dir = \"/home/raf_pc/Kemal/Temp/mouse\"\n",
    "data_repo_dir = \"/home/raf_pc/Kemal/Data/sam_arpat\"\n",
    "script_path_infrastructure = \"/home/raf_pc/Kemal/RiboSeqAnalysis/infrastructure/\"\n",
    "\n",
    "disomes = [os.path.join(data_repo_dir, i) for i in [\"SRR9715828.sam\", \"SRR9715826.sam\"]]\n",
    "monosomes = [os.path.join(data_repo_dir, i) for i in [\"SRR1930189.sam\", \"SRR1930188.sam\"]]\n",
    "\n",
    "\n",
    "I = Infrastructre(temp_repo_dir,\n",
    "                  riboseq_assign_at=-15,\n",
    "                  riboseq_assign_to=\"best_transcript\",\n",
    "                  ensembl_release=102,\n",
    "                  organism=\"mus_musculus\",\n",
    "                  include_gene3d=True,\n",
    "                  verbose=True)\n",
    "\n",
    "I.riboseq_sixtymers = RiboSeqSixtymers(I.temp_repo_dir, monosomes, disomes, \"sixtymers\",\n",
    "                                       I.riboseq_assign_at, I.riboseq_assign_to,\n",
    "                                       I.protein_genome, I.gene_info,\n",
    "                                       exclude_genes=I.exclude_genes, verbose=I.verbose,\n",
    "                                       footprint_len_experiment=list(range(45,71)),  # From paper\n",
    "                                       footprint_len_translatome=list(range(26,36))  # From paper\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I.riboseq_sixtymers.translatome.total_assigned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of RPKM values in imported data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the relationship between two riboseq data, ideally control vs experiment pairs like sixtymers versus translatome.\n",
    "<br>\n",
    "Note: To draw loglog plot, zero values were removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from scipy import stats \n",
    "import seaborn as sns\n",
    "from matplotlib import gridspec\n",
    "\n",
    "def compare_two_riboseq(arr1, arr2, narr1, narr2, general=None): # translatome, sixtymers:\n",
    "    # Plot the result as histograms\n",
    "    fig = plt.figure(figsize=(12, 5)) \n",
    "    if general: fig.suptitle(general, y=1.05, fontweight=\"bold\")\n",
    "    gs = fig.add_gridspec(1, 2, width_ratios=[1.25, 1])\n",
    "    axes0 = plt.subplot(gs[0])\n",
    "    axes0.set_yscale('log')\n",
    "    axes0.set_ylabel('Gene count')\n",
    "    axes0.set_xlabel(f'RPKM')\n",
    "    values = np.concatenate([arr1,arr2])\n",
    "    labels = np.array([narr1] * len(arr1) + [narr2] * len(arr2))\n",
    "    df_temp = pd.DataFrame.from_dict(dict(zip([\"RPKM\", \"Label\"], [values, labels])))\n",
    "    sns.histplot(df_temp, x=\"RPKM\", hue=\"Label\", multiple=\"dodge\", ax=axes0, bins=30)\n",
    "    \n",
    "    # Fit the linear line to the loglog\n",
    "    non_zero = np.intersect1d(np.nonzero(arr1), np.nonzero(arr2))\n",
    "    arr1_log = np.log10(arr1[non_zero])\n",
    "    arr2_log = np.log10(arr2[non_zero])\n",
    "    results = sm.OLS(arr2_log, sm.add_constant(arr1_log)).fit()\n",
    "    x_data_log = np.linspace(arr1_log.min(), arr1_log.max(), 1000)\n",
    "    y_data_log = x_data_log * results.params[1] + results.params[0]\n",
    "\n",
    "    # Plot the result\n",
    "    axes1 = plt.subplot(gs[1])\n",
    "    axes1.set_xlabel(f\"{narr1} RPKM (x)\")\n",
    "    axes1.set_ylabel(f\"{narr2} RPKM (y)\")\n",
    "    axes1.set_xscale('log')\n",
    "    axes1.set_yscale('log')\n",
    "    axes1.scatter(x=arr1[non_zero], y=arr2[non_zero], marker='.', edgecolors='none')\n",
    "    axes1.plot(10**x_data_log, 10**y_data_log, color=\"black\")\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.25)\n",
    "    textstr = '\\n'.join((\n",
    "        r'$log_{10}(y)=log_{10}(x)*%.2f + %.2f$' % (results.params[1], results.params[0]),\n",
    "        r'$y=x^{%.2f}*10^{%.2f}$' % (results.params[1], results.params[0]),\n",
    "        r'$R^2=%.2f$' % (results.rsquared,),\n",
    "        ))\n",
    "    axes1.text(0.025, 0.975, textstr, transform=axes1.transAxes, verticalalignment='top', horizontalalignment=\"left\", bbox=props, alpha=1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Check the correlation between RPKM values of translatome and experiment for sixytmer data\n",
    "    corr_nonzero = stats.pearsonr(tt_rpkms[non_zero], ex_rpkms[non_zero])\n",
    "    corr_all = stats.pearsonr(tt_rpkms, ex_rpkms)\n",
    "    print(\"Pearson correlation (only nonzero): %.4f, where p=%.2f\" % (corr_nonzero[0], corr_nonzero[1]))\n",
    "    print(\"Pearson correlation (all): %.4f, where p=%.2f\" % (corr_all[0], corr_all[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total translatome and experiment RPKM values for sixytmer data.\n",
    "tt_rpkms = np.array([I.riboseq_sixtymers.translatome.calculate_rpkm_genes(g) for g in I.gene_list])\n",
    "ex_rpkms = np.array([I.riboseq_sixtymers.experiment.calculate_rpkm_genes(g) for g in I.gene_list])\n",
    "compare_two_riboseq(tt_rpkms, ex_rpkms, \"Monosomes\", \"Disomes\", \"Arpat's Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Peak Prioritization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smooth while preserve peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "window_types = ('flat', 'hanning', 'hamming', 'bartlett', 'blackman')\n",
    "window_range = np.arange(3, 111, 2)\n",
    "save_metadata_path = os.path.join(temp_repo_dir, \"jupyter_smoothen_window_peak_detection.joblib\")\n",
    "try:  # Because it takes very long, as written very inefficiently.\n",
    "    all_peak = joblib.load(save_metadata_path)\n",
    "except FileNotFoundError:\n",
    "    all_peak = list()\n",
    "    for window in window_types:\n",
    "        genome_response_peak = list()\n",
    "        for gene_id in I.gene_list:\n",
    "            exp_rpkm = I.riboseq_sixtymers.experiment.calculate_rpkm_genes(gene_id)\n",
    "            tra_rpkm = I.riboseq_sixtymers.translatome.calculate_rpkm_genes(gene_id)\n",
    "            if exp_rpkm > 1 and tra_rpkm > 1:\n",
    "                exp_rpm_bf = I.riboseq_sixtymers.experiment.calculate_rpm_positions(gene_id)\n",
    "                window_list = list()\n",
    "                for window_len in window_range: \n",
    "                    try:\n",
    "                        exp_rpm_s = smooth_array(exp_rpm_bf, window_len=window_len, window=window)\n",
    "                        calc = len(find_peaks(exp_rpm_s)[0]) / len(exp_rpm_s) * 1000  # number of peaks detected\n",
    "                    except AssertionError:\n",
    "                        calc = np.nan\n",
    "                    window_list.append(calc)\n",
    "                genome_response_peak.append(window_list)\n",
    "        all_peak.append(genome_response_peak)\n",
    "    all_peak = np.array(all_peak)\n",
    "    joblib.dump(all_peak, save_metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kneed import KneeLocator\n",
    "fig, ax = plt.subplots(1,5, figsize=(15, 3), sharex=True, sharey=True, constrained_layout=True) \n",
    "plt.suptitle(\"Response to Smoothening\", y=1.1, fontweight=\"bold\")\n",
    "x_data = window_range\n",
    "CONFIDENCE = 0.999\n",
    "for k, window in enumerate(window_types):\n",
    "    arr = np.array(all_peak[k])\n",
    "    # Statistics\n",
    "    y_data = np.nanmean(arr, axis=0)\n",
    "    se = np.array(stats.sem(arr, nan_policy='omit')) # standard error\n",
    "    n = len(arr) - np.sum(np.isnan(arr), axis=0)\n",
    "    ci_l, ci_h = stats.t.interval(CONFIDENCE, n-1, loc=y_data, scale=se)\n",
    "    # Find elbow\n",
    "    kn = KneeLocator(x_data, y_data, curve='convex', direction='decreasing')\n",
    "    knee_x, knee_y = kn.knee, kn.knee_y\n",
    "    # Plot\n",
    "    ax[k].plot(x_data, y_data, linewidth=0.5, color=\"black\")\n",
    "    ax[k].fill_between(x_data, ci_l, ci_h, alpha=0.5)        \n",
    "    ax[k].scatter(knee_x, knee_y, color=\"red\")\n",
    "    ax[k].text(0.925, 0.925, f\"'{window.capitalize()}'\\nPosititon: {knee_x}\\nValue: {round(knee_y,4)}\", transform=ax[k].transAxes, verticalalignment='top', horizontalalignment=\"right\", alpha=1)\n",
    "fig.text(0.5, - 0.05, 'Window Length', ha='center')\n",
    "fig.text(-0.02, 0.5, \"Mean of Peak Count per Kilobase\", va='center', rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means, 'hanning' smoothing with window length 23 will be the choice. I only tried convolutional smoothing with various window types. For now, I will move forward with this one, but please note that there could be many option for this step. Some of them are:\n",
    "- Low pass Butterworth filter\n",
    "- Forrier transform and get a slice\n",
    "- Using other kernels like gaussian kernel\n",
    "- Wiener filter, scipy filters like lfilter, Kalman filter\n",
    "- tsmoothie package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "gene_id = I.gene_list[0]\n",
    "# Check 0, 7, 11\n",
    "# Check 30 for single peak. Compare with 25\n",
    "gene_rpm_vals = np.mean(I.riboseq_sixtymers.experiment.gene_assignments[gene_id], axis=0)\n",
    "smooth1 = smooth_array(gene_rpm_vals, window=\"hanning\", window_len = 25)\n",
    "smooth2 = smooth_array(gene_rpm_vals, window=\"hanning\", window_len = 55)\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "plt.plot(gene_rpm_vals / gene_rpm_vals.max(), alpha=0.5, color=\"gray\")\n",
    "plt.plot(smooth1 / smooth1.max()); plt.plot(smooth2 / smooth2.max())\n",
    "plt.ylabel(\"Signal\"); plt.xlabel(\"Position\")\n",
    "gene_names = \", \".join(I.gene_info[gene_id].gene_names)\n",
    "plt.title(f\"{gene_id}: {gene_names}\", y=1.05, fontweight=\"bold\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peak Detection 1: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global threshold for peak height. RPM values for gene positions are normalized by gene translatome RPM value, like Arpat et. al. did, but not pairwise position normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_heights = list()\n",
    "window_len = 25\n",
    "for gene_id in I.gene_list:\n",
    "    exp_rpkm = I.riboseq_sixtymers.experiment.calculate_rpkm_genes(gene_id)\n",
    "    tra_rpkm = I.riboseq_sixtymers.translatome.calculate_rpkm_genes(gene_id)\n",
    "    if exp_rpkm > 1 and tra_rpkm > 1:\n",
    "        exp_rpm_bs = I.riboseq_sixtymers.experiment.calculate_rpm_positions(gene_id)\n",
    "        # normalize with translatome rpm\n",
    "        rpm_gene = I.riboseq_sixtymers.translatome.calculate_rpm_genes(gene_id)\n",
    "        if len(exp_rpm_bs) > window_len:\n",
    "            exp_rpm_s = smooth_array(exp_rpm_bs, window_len=window_len, window=\"hanning\") / rpm_gene\n",
    "            peak_heights.append(exp_rpm_s[find_peaks(exp_rpm_s)[0]])\n",
    "print(f\"Number of gene: {len(peak_heights)}\")\n",
    "peak_heights = np.concatenate(peak_heights, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_peak_height = np.log10(peak_heights)\n",
    "log_peak_height_for_1 = log_peak_height.copy()  # for later use\n",
    "fit_mu, fit_std  = stats.norm.fit(log_peak_height)\n",
    "x_data_mock = np.linspace(log_peak_height.min(), log_peak_height.max(), 1000)\n",
    "y_data_fit = stats.norm.pdf(x_data_mock, fit_mu, fit_std)\n",
    "fig, ax = plt.subplots(1,1, figsize=(5, 4), constrained_layout=True) \n",
    "ax.set_title(\"Peak Hight Distribution\", fontweight=\"bold\", y=1.05)\n",
    "ax.set_xlabel(r\"$Log_{10}$(Normalized Peak Height)\")\n",
    "ax.set_ylabel(f\"Density\")\n",
    "ax.hist(log_peak_height, density=True, bins=512, alpha=0.5)\n",
    "ax.plot(x_data_mock, y_data_fit, color=\"black\", linestyle='--')\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.25)\n",
    "textstr = \"Normal\\n\" + '\\n'.join((r'$\\mu=$%.2f' % fit_mu, r'$\\sigma=$%.2f' % fit_std))\n",
    "ax.text(0.95, 0.95, textstr, transform=ax.transAxes, verticalalignment='top', horizontalalignment=\"right\", bbox=props, alpha=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_detection_inecik_1(gene_id, threshold, window=\"hanning\", window_len=25):\n",
    "    try:\n",
    "        exp_rpkm = I.riboseq_sixtymers.experiment.calculate_rpkm_genes(gene_id)\n",
    "        tra_rpkm = I.riboseq_sixtymers.translatome.calculate_rpkm_genes(gene_id)\n",
    "        exp_rpm_bs = I.riboseq_sixtymers.experiment.calculate_rpm_positions(gene_id)\n",
    "        assert exp_rpkm > 1 and tra_rpkm > 1\n",
    "        assert len(exp_rpm_bs) > window_len\n",
    "        rpm_gene = I.riboseq_sixtymers.translatome.calculate_rpm_genes(gene_id)\n",
    "        exp_rpm_s = smooth_array(exp_rpm_bs, window_len=window_len, window=window) / rpm_gene\n",
    "        peaks = find_peaks(exp_rpm_s)[0]\n",
    "        peak_values = exp_rpm_s[peaks]\n",
    "        peak_values_thresholded = np.log10(peak_values) > threshold\n",
    "        return peaks[peak_values_thresholded]\n",
    "    except AssertionError:\n",
    "        return np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "gene_id = I.gene_list[0]\n",
    "threshold_1 = np.percentile(log_peak_height_for_1, 90)\n",
    "peaks_example = peak_detection_inecik_1(gene_id, threshold_1)\n",
    "print(f\"Peaks for {gene_id}: {peaks_example}\")\n",
    "print(f\"Threshold: {round(threshold_1, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I.riboseq_sixtymers.stalling_peaks_inecik_1(gene_id, percentile=90, min_rpkm_sixtymers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peak Detection 2: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global threshold for peak height times peak prominence, considering peak as a triangle and calculating the area. RPM values for gene positions are normalized by gene translatome RPM value, but not pairwise position normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks, peak_widths, peak_prominences\n",
    "x = np.linspace(0, 6 * np.pi, 1000)\n",
    "x = np.sin(x) + 0.6 * np.sin(3.6 * x)\n",
    "peaks, _ = find_peaks(x)\n",
    "results_full = peak_widths(x, peaks, rel_height=1, wlen=290)\n",
    "fig = plt.figure(figsize=(12,3))\n",
    "plt.plot(x)\n",
    "plt.title(\"Example Sixtymer Data\", fontweight=\"bold\", y=1.05)\n",
    "plt.plot(peaks, x[peaks], \"x\")\n",
    "plt.hlines(*results_full[1:], color=\"C3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this method is based on calculating triangular area covered by the peak width and peak prominence. This will allow us to get rid of the noise in the peaks. Since it also takes the width, it should be more robust method in terms of biological relevance. Prominence measures how much a peak stands out from the surrounding baseline of the signal and is defined as the vertical distance between the peak and its lowest contour line. For this reason, background signal will be canceled out automatically.\n",
    "\n",
    "Here, 'wlen' is a parameter that should be optimized, because a large wlen cause data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter optimization for 'wlen'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assume that, as we increase the value of wlen, we expect to see peaks with much longer width. The elbow point will help us select an optimal 'wlen'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wlen_range = np.arange(40, 1200, 10)\n",
    "wlen_optimize = list()\n",
    "save_metadata_path = os.path.join(temp_repo_dir, \"jupyter_wlen_parameter_peak_detection.joblib\")\n",
    "try:  # Because it takes very long, as written very inefficiently.\n",
    "    wlen_optimize = joblib.load(save_metadata_path)\n",
    "except FileNotFoundError:\n",
    "    for wlen in wlen_range:\n",
    "        peak_width_all = list()\n",
    "        for gene_id in I.gene_list:\n",
    "            exp_rpkm = I.riboseq_sixtymers.experiment.calculate_rpkm_genes(gene_id)\n",
    "            tra_rpkm = I.riboseq_sixtymers.translatome.calculate_rpkm_genes(gene_id)\n",
    "            if exp_rpkm > 1 and tra_rpkm > 1:\n",
    "                exp_rpm_bs = I.riboseq_sixtymers.experiment.calculate_rpm_positions(gene_id)\n",
    "                # normalize with translatome rpm\n",
    "                rpm_gene = I.riboseq_sixtymers.translatome.calculate_rpm_genes(gene_id)\n",
    "                if len(exp_rpm_bs) > window_len:\n",
    "                    exp_rpm_s = smooth_array(exp_rpm_bs, window_len=25, window=\"hanning\") / rpm_gene\n",
    "                    peaks, _ = find_peaks(exp_rpm_s)\n",
    "                    witdhs = peak_widths(exp_rpm_s, rel_height=1, peaks=peaks, wlen=wlen)\n",
    "                    peak_width_all.extend(witdhs[0])\n",
    "        wlen_optimize.append(peak_width_all)\n",
    "    wlen_optimize = np.array(wlen_optimize)\n",
    "    joblib.dump(wlen_optimize, save_metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kneed import KneeLocator\n",
    "fig, ax = plt.subplots(1,1, figsize=(6, 4), sharex=True, sharey=True, constrained_layout=True) \n",
    "plt.suptitle(\"Response to Increasing 'wlen' Parameter \", y=1.1, fontweight=\"bold\")\n",
    "x_data = wlen_range\n",
    "CONFIDENCE = 0.999\n",
    "arr = wlen_optimize.T\n",
    "# Statistics\n",
    "y_data = np.nanmean(arr, axis=0)\n",
    "se = np.array(stats.sem(arr, nan_policy='omit')) # standard error\n",
    "n = len(arr) - np.sum(np.isnan(arr), axis=0)\n",
    "ci_l, ci_h = stats.t.interval(CONFIDENCE, n-1, loc=y_data, scale=se)\n",
    "# Find elbow\n",
    "kn = KneeLocator(x_data, y_data, curve='concave', direction='increasing')\n",
    "knee_x, knee_y = kn.knee, kn.knee_y\n",
    "# Plot\n",
    "ax.plot(x_data, y_data, linewidth=0.5, color=\"black\")\n",
    "ax.fill_between(x_data, ci_l, ci_h, alpha=0.5)        \n",
    "ax.scatter(knee_x, knee_y, color=\"red\")\n",
    "ax.text(0.925, 0.055, f\"Posititon: {knee_x}\\nValue: {round(knee_y,4)}\", transform=ax.transAxes, verticalalignment='bottom', horizontalalignment=\"right\", alpha=1)\n",
    "fig.text(0.5, - 0.05, \"Parameter 'wlen'\", ha='center')\n",
    "fig.text(-0.02, 0.5, \"Mean of Width\", va='center', rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, wlen=290 is the value I want to move with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global threshold and the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is similar to above, but this time aforementioned triangular area will be used for a peak. Here, I will try to find out a good thredhold for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_calculation = list()\n",
    "peak_prominences_for_pd_4 = list()\n",
    "for gene_id in I.gene_list:\n",
    "    exp_rpkm = I.riboseq_sixtymers.experiment.calculate_rpkm_genes(gene_id)\n",
    "    tra_rpkm = I.riboseq_sixtymers.translatome.calculate_rpkm_genes(gene_id)\n",
    "    if exp_rpkm > 1 and tra_rpkm > 1:\n",
    "        exp_rpm_bs = I.riboseq_sixtymers.experiment.calculate_rpm_positions(gene_id)\n",
    "        # normalize with translatome rpm\n",
    "        rpm_gene = I.riboseq_sixtymers.translatome.calculate_rpm_genes(gene_id)\n",
    "        if len(exp_rpm_bs) > window_len:\n",
    "            exp_rpm_s = smooth_array(exp_rpm_bs, window_len=25, window=\"hanning\") / rpm_gene\n",
    "            peaks, _ = find_peaks(exp_rpm_s)\n",
    "            calc_prominences = peak_prominences(exp_rpm_s, peaks=peaks, wlen=290)\n",
    "            calc_witdhs = peak_widths(exp_rpm_s, rel_height=1, peaks=peaks, prominence_data=calc_prominences, wlen=290)\n",
    "            peak_calculation.append(calc_prominences[0] * calc_witdhs[0])\n",
    "            peak_prominences_for_pd_4.extend(list(calc_prominences[0]))\n",
    "print(f\"Number of gene: {len(peak_calculation)}\")\n",
    "peak_calculation = np.concatenate(peak_calculation, axis=0)\n",
    "peak_prominences_for_pd4_log = np.log10(np.array(peak_prominences_for_pd_4))  # For later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_peak_height = np.log10(peak_calculation)\n",
    "log_peak_height_for_2 = log_peak_height.copy()  # for later use\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 4), constrained_layout=True) \n",
    "ax.set_title(\"Peak Area Distribution\", fontweight=\"bold\", y=1.05)\n",
    "ax.set_xlabel(r\"$Log_{10}$(Peak Area)\")\n",
    "ax.set_ylabel(f\"Density\")\n",
    "ax.hist(log_peak_height, density=True, bins=512, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I calculated fitting by running 'universal_fitter' function first, which enabled me to know which probability distribution best represents the data. Note that I do not use the parameters and the fit for this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_detection_inecik_2(gene_id, threshold, window=\"hanning\", window_len=25, wlen=290):\n",
    "    try:\n",
    "        exp_rpkm = I.riboseq_sixtymers.experiment.calculate_rpkm_genes(gene_id)\n",
    "        tra_rpkm = I.riboseq_sixtymers.translatome.calculate_rpkm_genes(gene_id)\n",
    "        exp_rpm_bs = I.riboseq_sixtymers.experiment.calculate_rpm_positions(gene_id)\n",
    "        assert exp_rpkm > 1 and tra_rpkm > 1\n",
    "        assert len(exp_rpm_bs) > window_len\n",
    "        rpm_gene = I.riboseq_sixtymers.translatome.calculate_rpm_genes(gene_id)\n",
    "        exp_rpm_s = smooth_array(exp_rpm_bs, window_len=window_len, window=window) / rpm_gene\n",
    "        # Calculations\n",
    "        peaks, _ = find_peaks(exp_rpm_s)\n",
    "        calc_prominences = peak_prominences(exp_rpm_s, peaks=peaks, wlen=wlen)\n",
    "        calc_witdhs = peak_widths(exp_rpm_s, rel_height=1, peaks=peaks, prominence_data=calc_prominences, wlen=290)\n",
    "        calcs = calc_prominences[0] * calc_witdhs[0]\n",
    "        return peaks[np.log10(calcs) > threshold]\n",
    "    except AssertionError:\n",
    "        return np.array([])\n",
    "# Array'in baÅÄ±na ve sonuna 0 ekle Ã§Ã¼nkÃ¼ baÅ ve sondaki pikleri algÄ±lamÄ±yor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "gene_id = I.gene_list[0]\n",
    "threshold_2 = np.percentile(log_peak_height_for_2, 90)\n",
    "peaks_example = peak_detection_inecik_2(gene_id, threshold_2)\n",
    "print(f\"Peaks for {gene_id}: {peaks_example}\")\n",
    "print(f\"Threshold: {round(threshold_2, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I.riboseq_sixtymers.stalling_peaks_inecik_2(gene_id, percentile=90, window_len=25, min_rpkm_sixtymers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peak Detection 4: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peak detection 2 has a problem of ignoring very sharp but not wide peaks. There can be a method which I determine peaks by just checking the prominences (wlen is threfore used) instead of triangular area. This will ensure to disregard the unimportant peaks in peak clusters while keeping very sharp peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(peak_prominences_for_pd4_log, bins=256, density=True, alpha=0.5)\n",
    "plt.title(\"Peak Prominences\", fontweight=\"bold\", y=1.05)\n",
    "plt.xlabel(r\"$Log_{10}$(Peak Prominence)\")\n",
    "plt.ylabel(f\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_detection_inecik_4(gene_id, threshold, window=\"hanning\", window_len=25, wlen=290):\n",
    "    try:\n",
    "        exp_rpkm = I.riboseq_sixtymers.experiment.calculate_rpkm_genes(gene_id)\n",
    "        tra_rpkm = I.riboseq_sixtymers.translatome.calculate_rpkm_genes(gene_id)\n",
    "        exp_rpm_bs = I.riboseq_sixtymers.experiment.calculate_rpm_positions(gene_id)\n",
    "        assert exp_rpkm > 1 and tra_rpkm > 1\n",
    "        assert len(exp_rpm_bs) > window_len\n",
    "        rpm_gene = I.riboseq_sixtymers.translatome.calculate_rpm_genes(gene_id)\n",
    "        exp_rpm_s = smooth_array(exp_rpm_bs, window_len=window_len, window=window) / rpm_gene\n",
    "        # Calculations\n",
    "        peaks, _ = find_peaks(exp_rpm_s)\n",
    "        calc_prominences = peak_prominences(exp_rpm_s, peaks=peaks, wlen=wlen)\n",
    "        return peaks[np.log10(calc_prominences[0]) > threshold]\n",
    "    except AssertionError:\n",
    "        return np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "gene_id = I.gene_list[0]\n",
    "threshold_4 = np.percentile(peak_prominences_for_pd4_log, 90)\n",
    "peaks_example = peak_detection_inecik_4(gene_id, threshold_4)\n",
    "print(f\"Peaks for {gene_id}: {peaks_example}\")\n",
    "print(f\"Threshold: {round(threshold_4, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I.riboseq_sixtymers.stalling_peaks_inecik_4(gene_id, percentile=90, min_rpkm_sixtymers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peak Detection 3: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It depends on the idea explained previous method. However, if we directly multiply width with prominence, we will end up with data, which mostly represents height (actually, prominence), because their scale is very different (prominence values are very small in general). This is okay because the highest width is assigned to the largest peak for a given are. Actually, previous method clears up the first methods finding in some sense. For a given, 'wlen', it prioritizes the highest peak. Nevertheless, previous method cannot capture wide peaks First I want to find out probability distributions of both width and prominence, which help me to evaluate cumulative distribution function of a given value. I will use the output in calculation of triangular area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prominence and width distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTRIBUTIONS = [\"alpha\", \"anglit\", \"arcsine\", \"argus\", \"beta\", \"betaprime\", \"bradford\", \"burr\", \"burr12\", \"cauchy\", \"chi\", \"chi2\", \"cosine\", \"crystalball\", \"dgamma\", \"dweibull\", \"erlang\", \"expon\", \"exponnorm\", \"exponweib\", \"exponpow\", \"f\", \"fatiguelife\", \"fisk\", \"foldcauchy\", \"foldnorm\", \"genlogistic\", \"gennorm\", \"genpareto\", \"genexpon\", \"genextreme\", \"gausshyper\", \"gamma\", \"gengamma\", \"genhalflogistic\", \"geninvgauss\", \"gilbrat\", \"gompertz\", \"gumbel_r\", \"gumbel_l\", \"halfcauchy\", \"halflogistic\", \"halfnorm\", \"halfgennorm\", \"hypsecant\", \"invgamma\", \"invgauss\", \"invweibull\", \"johnsonsb\", \"johnsonsu\", \"kappa4\", \"kappa3\", \"ksone\", \"kstwo\", \"kstwobign\", \"laplace\", \"laplace_asymmetric\", \"levy\", \"levy_l\", \"logistic\", \"loggamma\", \"loglaplace\", \"lognorm\", \"loguniform\", \"lomax\", \"maxwell\", \"mielke\", \"moyal\", \"nakagami\", \"norm\", \"norminvgauss\", \"pareto\", \"pearson3\", \"powerlaw\", \"powerlognorm\", \"powernorm\", \"rdist\", \"rayleigh\", \"rice\", \"recipinvgauss\", \"semicircular\", \"skewnorm\", \"t\", \"trapezoid\", \"triang\", \"truncexpon\", \"truncnorm\", \"uniform\", \"vonmises\", \"vonmises_line\", \"wald\", \"weibull_min\", \"weibull_max\", \"wrapcauchy\"]\n",
    "def universal_fitter(arr, dists, bins, verbose=True):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        result = list()\n",
    "        for distribution_name in dists:\n",
    "            if verbose: print(distribution_name, end=\": \")\n",
    "            try:\n",
    "                distribution = eval(\"stats.\" + distribution_name)\n",
    "                y_exp, x_data = np.histogram(arr, bins, density=True)\n",
    "                fit_params = distribution.fit(arr)\n",
    "                y_predicted = distribution.pdf(x_data[:-1], *fit_params)\n",
    "                mean_sqrt_err = np.sum(np.power(y_predicted - y_exp, 2)) / (len(x_data)-1)\n",
    "                result.append(mean_sqrt_err)\n",
    "            except:\n",
    "                result.append(np.nan)\n",
    "            if verbose: print(round(mean_sqrt_err, 6), end=\" ... Winner: \")\n",
    "            if verbose: print(DISTRIBUTIONS[result.index(min(result))])\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_calculation_z = [[],[]]\n",
    "for gene_id in I.gene_list:\n",
    "    exp_rpkm = I.riboseq_sixtymers.experiment.calculate_rpkm_genes(gene_id)\n",
    "    tra_rpkm = I.riboseq_sixtymers.translatome.calculate_rpkm_genes(gene_id)\n",
    "    if exp_rpkm > 1 and tra_rpkm > 1:\n",
    "        exp_rpm_bs = I.riboseq_sixtymers.experiment.calculate_rpm_positions(gene_id)\n",
    "        # normalize with translatome rpm\n",
    "        rpm_gene = I.riboseq_sixtymers.translatome.calculate_rpm_genes(gene_id)\n",
    "        if len(exp_rpm_bs) > window_len:\n",
    "            exp_rpm_s = smooth_array(exp_rpm_bs, window_len=25, window=\"hanning\") / rpm_gene\n",
    "            peaks, _ = find_peaks(exp_rpm_s)\n",
    "            calc_prominences = peak_prominences(exp_rpm_s, peaks=peaks, wlen=290)\n",
    "            calc_witdhs = peak_widths(exp_rpm_s, rel_height=1, peaks=peaks, prominence_data=calc_prominences, wlen=290)\n",
    "            peak_calculation_z[0].extend(list(calc_prominences[0]))\n",
    "            peak_calculation_z[1].extend(list(calc_witdhs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a, b = peak_calculation_z\n",
    "a, b = np.array(a), np.array(b)\n",
    "la = np.log(a)\n",
    "c = la > -18  # It is basically floating point errors etc\n",
    "a, b, la = a[c], b[c], la[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_h_additional = a.max()\n",
    "d = -np.log(a/a.max())\n",
    "# Below code was actually run. The result was 'fisk'. It takes so long so commented out.\n",
    "# res_d = universal_fitter(d, DISTRIBUTIONS, 512, verbose=False)\n",
    "# distribution = eval(\"stats.\" + \"DISTRIBUTIONS[res_d.index(min(res_d))]\"\n",
    "distribution = stats.fisk\n",
    "params_h  = distribution.fit(d)\n",
    "x_data_mock = np.linspace(d.min(), d.max(), 256)\n",
    "y_data_fit = distribution.pdf(x_data_mock, *params_h)\n",
    "# Plot\n",
    "plt.hist(d, bins=128, density=True, alpha=0.5)\n",
    "plt.plot(x_data_mock, y_data_fit, color=\"black\", linestyle='--')\n",
    "plt.title(\"Peak Prominence Distribution\", fontweight=\"bold\", y=1.05)\n",
    "plt.ylabel(\"Density\")\n",
    "plt.xlabel(r\"$-log(\\frac{h}{max(h)})$\")\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.25)\n",
    "textstr = \"Log-Logistic (Fisk)\\n\" + '\\n'.join(('c = %.2f' % params_h[0], r'loc = %.2f' % params_h[1], r'$scale = $%.2f' % params_h[2]))\n",
    "ax = plt.gca()\n",
    "ax.text(0.95, 0.95, textstr, transform=ax.transAxes, verticalalignment='top', horizontalalignment=\"right\", bbox=props, alpha=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that smaller values are actually higher peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "e = b[b != 24]  # It is just a byproduct of the hanning window_len process.\n",
    "# Below code was actually run. The result was 'fisk'. It takes so long so commented out.\n",
    "# res_e = universal_fitter(e, DISTRIBUTIONS, 512, verbose=False)\n",
    "# distribution = eval(\"stats.\" + \"DISTRIBUTIONS[res.index(min(res))]\"\n",
    "distribution = stats.fisk\n",
    "params_w  = distribution.fit(e)\n",
    "x_data_mock = np.linspace(e.min(), e.max(), 256)\n",
    "y_data_fit = distribution.pdf(x_data_mock, *params_w)\n",
    "# Plot\n",
    "plt.hist(e, bins=128, density=True, alpha=0.5)\n",
    "plt.plot(x_data_mock, y_data_fit, color=\"black\", linestyle='--')\n",
    "plt.title(\"Peak Width Distribution\", fontweight=\"bold\", y=1.05)\n",
    "plt.ylabel(\"Density\")\n",
    "plt.xlabel(\"Width\")\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.25)\n",
    "textstr = \"Log-Logistic (Fisk)\\n\" + '\\n'.join(('c = %.2f' % params_w[0], r'loc = %.2f' % params_w[1], r'$scale = $%.2f' % params_w[2]))\n",
    "ax = plt.gca()\n",
    "ax.text(0.95, 0.95, textstr, transform=ax.transAxes, verticalalignment='top', horizontalalignment=\"right\", bbox=props, alpha=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "##### Bivariate distribution of log-logistic (fisk) distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At upper left corner, the peaks of interest are found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 1000\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4), constrained_layout=True) \n",
    "plt.suptitle(\"Bivariate Probability Density Function\", y=1.1, fontweight=\"bold\")\n",
    "for i, (y_lims, x_lims) in enumerate(zip(((0, 20), (5,15)), ((0,300), (0,50)))):\n",
    "    x_data_h = np.linspace(*y_lims, resolution)\n",
    "    dist_h = stats.fisk.pdf(x_data_h, *params_h)\n",
    "    x_data_w = np.linspace(*x_lims, resolution)\n",
    "    dist_w = stats.fisk.pdf(x_data_w, *params_w)\n",
    "    dist_h = dist_h.reshape(resolution, 1)\n",
    "    dist_w = dist_w.reshape(1, resolution)\n",
    "    matrice = (dist_h.reshape(resolution, 1) * dist_w.reshape(1, resolution))\n",
    "    matrice = pd.DataFrame(matrice, columns=map(int, x_data_w), index=map(int, x_data_h))\n",
    "    sns.heatmap(matrice, ax=ax[i], xticklabels=False, yticklabels=False, cbar=False)\n",
    "fig.text(0.5, - 0.05, 'Peak Width', ha='center')\n",
    "fig.text(-0.05, 0.5, \"$log_{10}$(Normalized Prominence)\", va='center', rotation='vertical')\n",
    "ax[0].set_title(\"Whole range\", y=1.1)\n",
    "ax[1].set_title(\"Close up\", y=1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 1000\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4), constrained_layout=True) \n",
    "plt.suptitle(\"Bivariate Cumulative Density Function\", y=1.1, fontweight=\"bold\")\n",
    "for i, (y_lims, x_lims) in enumerate(zip(((0, 20), (5,15)), ((0,300), (0,50)))):\n",
    "    x_data_h = np.linspace(*y_lims, resolution)\n",
    "    dist_h = stats.fisk.cdf(x_data_h, *params_h)\n",
    "    x_data_w = np.linspace(*x_lims, resolution)\n",
    "    dist_w = 1 - stats.fisk.cdf(x_data_w, *params_w)\n",
    "    dist_h = dist_h.reshape(resolution, 1)\n",
    "    dist_w = dist_w.reshape(1, resolution)\n",
    "    matrice = (dist_h.reshape(resolution, 1) * dist_w.reshape(1, resolution))\n",
    "    matrice = pd.DataFrame(matrice, columns=map(int, x_data_w), index=map(int, x_data_h))\n",
    "    sns.heatmap(matrice, ax=ax[i], xticklabels=False, yticklabels=False, cbar=False)\n",
    "fig.text(0.5, - 0.05, 'Peak Width', ha='center')\n",
    "fig.text(-0.05, 0.5, \"$log_{10}$(Normalized Prominence)\", va='center', rotation='vertical')\n",
    "ax[0].set_title(\"Whole range\", y=1.1)\n",
    "ax[1].set_title(\"Close up\", y=1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The peaks at upper left are the peaks we are interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prominence and width distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_prominence(x, params_h_additional, params):\n",
    "    x_logged = -np.log(x/params_h_additional)\n",
    "    cumulative_prob = stats.fisk.cdf(x_logged, *params)  # because smaller values are higher peaks\n",
    "    return cumulative_prob\n",
    "\n",
    "def probability_width(x, params):\n",
    "    cumulative_prob = stats.fisk.cdf(x, *params)\n",
    "    return 1 - cumulative_prob  # essentially this is survival function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_detection_inecik_3(gene_id, threshold, par_h_a, par_h, par_w,\n",
    "                            window=\"hanning\", window_len=25, wlen=290):\n",
    "    try:\n",
    "        exp_rpkm = I.riboseq_sixtymers.experiment.calculate_rpkm_genes(gene_id)\n",
    "        tra_rpkm = I.riboseq_sixtymers.translatome.calculate_rpkm_genes(gene_id)\n",
    "        exp_rpm_bs = I.riboseq_sixtymers.experiment.calculate_rpm_positions(gene_id)\n",
    "        assert exp_rpkm > 1 and tra_rpkm > 1\n",
    "        assert len(exp_rpm_bs) > window_len\n",
    "        rpm_gene = I.riboseq_sixtymers.translatome.calculate_rpm_genes(gene_id)\n",
    "        exp_rpm_s = smooth_array(exp_rpm_bs, window_len=window_len, window=window) / rpm_gene\n",
    "        peaks, _ = find_peaks(exp_rpm_s)\n",
    "        calc_prominences = peak_prominences(exp_rpm_s, peaks=peaks, wlen=wlen)\n",
    "        calc_witdhs = peak_widths(exp_rpm_s, rel_height=1, peaks=peaks, prominence_data=calc_prominences, wlen=wlen)\n",
    "        peak_prominence_probs = probability_prominence(calc_prominences[0], par_h_a, par_h)\n",
    "        peak_witdhs_probs = probability_width(calc_witdhs[0], par_w)\n",
    "        bivariate_cumulative = peak_prominence_probs * peak_witdhs_probs\n",
    "        thresholded = bivariate_cumulative < threshold        \n",
    "        return peaks[thresholded]\n",
    "    except AssertionError:\n",
    "        return np.array([])\n",
    "# Array'in baÅÄ±na ve sonuna 0 ekle Ã§Ã¼nkÃ¼ baÅ ve sondaki pikleri algÄ±lamÄ±yor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "gene_id = I.gene_list[0]\n",
    "threshold_3 = 0.005\n",
    "peaks_example = peak_detection_inecik_3(gene_id, threshold_3, params_h_additional, params_h, params_w)\n",
    "print(f\"Peaks for {gene_id}: {peaks_example}\")\n",
    "print(f\"Threshold: {round(threshold_3, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I.riboseq_sixtymers.stalling_peaks_inecik_3(gene_id, probability=0.005, min_rpkm_sixtymers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Peak Detection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_gene_with_large_rpkm(selected_gene_list):\n",
    "    while True:\n",
    "        gene_id = random.choice(I.riboseq_sixtymers.gene_list)\n",
    "        total_exp = I.riboseq_sixtymers.experiment.calculate_rpkm_genes(gene_id)\n",
    "        total_tra = I.riboseq_sixtymers.translatome.calculate_rpkm_genes(gene_id)\n",
    "        if total_exp > 1 and total_tra > 1 and gene_id not in selected_gene_list:\n",
    "            return total_exp, total_tra, gene_id    \n",
    "\n",
    "def random_gene_list_creator(gene_number):\n",
    "    plot_gene = list()\n",
    "    gene_id_list = list()\n",
    "    for _ in range(gene_number):\n",
    "        gene_info = find_gene_with_large_rpkm(gene_id_list)\n",
    "        plot_gene.append(gene_info)\n",
    "        gene_id_list.append(gene_info[2])\n",
    "    return plot_gene\n",
    "\n",
    "def start_gene_list_creator(gene_number, start_from):\n",
    "    plot_gene = list()\n",
    "    counter = 0\n",
    "    while len(plot_gene) != gene_number:\n",
    "        gene_id = I.gene_list[start_from + counter]\n",
    "        total_exp = I.riboseq_sixtymers.experiment.calculate_rpkm_genes(gene_id)\n",
    "        total_tra = I.riboseq_sixtymers.translatome.calculate_rpkm_genes(gene_id)\n",
    "        if total_exp > 1 and total_tra > 1:\n",
    "            plot_gene.append((total_exp, total_tra, gene_id),)\n",
    "        counter += 1\n",
    "    return plot_gene\n",
    "\n",
    "def see_examples(function, gene_list_plot, the_title, *args, **kwargs):\n",
    "    x, y = 1, 2\n",
    "    fig, axes = plt.subplots(x, y, figsize=(y * 7, x * 2))\n",
    "    fig.suptitle(the_title, y=1.1, fontweight=\"bold\")\n",
    "    counter = 0\n",
    "    for i1 in range(axes.shape[0]):\n",
    "        total_exp, total_tra, gene_id = gene_list_plot[counter]\n",
    "        counter += 1\n",
    "        rpm_tra = I.riboseq_sixtymers.translatome.calculate_rpm_genes(gene_id)\n",
    "        arr = smooth_array(I.riboseq_sixtymers.experiment.calculate_rpm_positions(gene_id), window_len=25, window=\"hanning\") / rpm_tra\n",
    "        peaks = function(gene_id, *args, **kwargs)\n",
    "        #axes[i1][i2].vlines(peaks, arr.min(),arr.max(), color=\"green\", linestyle=\"--\", linewidth=3)\n",
    "        axes[i1].plot(arr, alpha=1, color=\"salmon\")\n",
    "        axes[i1].scatter(peaks, [arr[p] for p in peaks], color=\"black\", alpha=1, s=25)\n",
    "        axes[i1].set_ylim(0, arr.max() * 1.35)\n",
    "        axes[i1].text(0.01, 0.99, f\"{gene_id} / Index {I.gene_list.index(gene_id)}\\nRPKMs: {round(total_exp,2)} - {round(total_tra,2)}\", fontsize=6, transform=axes[i1].transAxes, verticalalignment='top', horizontalalignment=\"left\")\n",
    "        axes[i1].text(0.99, 0.99, f\"Max: {round(arr.max(),5)}\\nPeaks: {len(peaks)}\", fontsize=6, transform=axes[i1].transAxes, verticalalignment='top', horizontalalignment=\"right\")\n",
    "        axes[i1].axes.get_yaxis().set_visible(False)\n",
    "        axes[i1].tick_params(labelsize=6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "threshold_1 = np.percentile(log_peak_height_for_1, 90)\n",
    "threshold_2 = np.percentile(log_peak_height_for_2, 90)\n",
    "threshold_3 = 0.02\n",
    "threshold_4 = np.percentile(peak_prominences_for_pd4_log, 90)\n",
    "print(f\"Threshold 1: {round(10**threshold_1, 5)}\\n\"\n",
    "      f\"Threshold 2: {round(10**threshold_2, 5)}\\n\" \n",
    "      f\"Threshold 3: {round(threshold_3, 5)}\\n\"\n",
    "      f\"Threshold 4: {round(threshold_4, 5)}\")\n",
    "gene_list_plot = start_gene_list_creator(2, 0)\n",
    "#gene_list_plot = random_gene_list_creator(2)\n",
    "see_examples(peak_detection_inecik_1, gene_list_plot, \"Peak Detection 1: Height\", threshold_1)\n",
    "see_examples(peak_detection_inecik_2, gene_list_plot, \"Peak Detection 2: Triangular Area\", threshold_2)\n",
    "see_examples(peak_detection_inecik_3, gene_list_plot, \"Peak Detection 3: Probability\", threshold_3, params_h_additional, params_h, params_w)\n",
    "see_examples(peak_detection_inecik_4, gene_list_plot, \"Peak Detection 4: Prominence\", threshold_4)\n",
    "see_examples(I.riboseq_sixtymers.stalling_peaks_arpat, gene_list_plot, \"Arpat's Method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I.riboseq_sixtymers.plot_result(I.gene_list[0], I.riboseq_sixtymers.stalling_peaks_arpat);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Response curves of the peak detection tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_point = 40\n",
    "perc_range = np.logspace(np.log10(99), np.log10(50), data_point)\n",
    "prob_range = np.logspace(np.log10(0.001), np.log10(0.5), data_point)\n",
    "save_metadata_path = os.path.join(temp_repo_dir, \"jupyter_peak_detection_response.joblib\")\n",
    "try:  # Because it takes very long, as written very inefficiently.\n",
    "    perc_all_1, perc_all_2, perc_all_3, perc_all_4 = joblib.load(save_metadata_path)\n",
    "except FileNotFoundError:\n",
    "    perc_all_1, perc_all_2, perc_all_3, perc_all_4 = list(), list(), list(), list()\n",
    "    for l in range(data_point):\n",
    "        threshold_1 = np.percentile(log_peak_height_for_1, perc_range[l])\n",
    "        threshold_2 = np.percentile(log_peak_height_for_2, perc_range[l])\n",
    "        threshold_3 = prob_range[l]\n",
    "        threshold_4 = np.percentile(peak_prominences_for_pd4_log, perc_range[l])\n",
    "        perc_peaks_1, perc_peaks_2, perc_peaks_3, perc_peaks_4 = list(), list(), list(), list()\n",
    "        for gene_id in I.gene_list:\n",
    "            exp_rpkm = I.riboseq_sixtymers.experiment.calculate_rpkm_genes(gene_id)\n",
    "            tra_rpkm = I.riboseq_sixtymers.translatome.calculate_rpkm_genes(gene_id)\n",
    "            if exp_rpkm < 1 or tra_rpkm < 1 or I.riboseq_sixtymers.translatome.gene_lengths[gene_id] < 25:\n",
    "                continue \n",
    "            perc_peaks_1.append(len(peak_detection_inecik_1(gene_id, threshold_1)))\n",
    "            perc_peaks_2.append(len(peak_detection_inecik_2(gene_id, threshold_2)))\n",
    "            perc_peaks_3.append(len(peak_detection_inecik_3(gene_id, threshold_3, params_h_additional, params_h, params_w)))\n",
    "            perc_peaks_4.append(len(peak_detection_inecik_4(gene_id, threshold_4)))\n",
    "        perc_all_1.append(perc_peaks_1)\n",
    "        perc_all_2.append(perc_peaks_2)\n",
    "        perc_all_3.append(perc_peaks_3)\n",
    "        perc_all_4.append(perc_peaks_4)\n",
    "    perc_all_1 = np.array(perc_all_1)\n",
    "    perc_all_2 = np.array(perc_all_2)\n",
    "    perc_all_3 = np.array(perc_all_3)\n",
    "    perc_all_4 = np.array(perc_all_4)\n",
    "    joblib.dump((perc_all_1, perc_all_2, perc_all_3, perc_all_4), save_metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=(12, 3), constrained_layout=True) \n",
    "plt.suptitle(\"Response Curves of Peak Detection Methods\", y=1.1, fontweight=\"bold\")\n",
    "for i in range(4):\n",
    "    x_data = perc_range if i != 2 else prob_range\n",
    "    arr = eval(f\"perc_all_{i+1}.T\")\n",
    "    # Statistics\n",
    "    y_data = np.nanmean(arr, axis=0)\n",
    "    se = np.array(stats.sem(arr, nan_policy='omit')) # standard error\n",
    "    n = len(arr) - np.sum(np.isnan(arr), axis=0)\n",
    "    ci_l, ci_h = stats.t.interval(CONFIDENCE, n-1, loc=y_data, scale=se)\n",
    "    # Plot\n",
    "    ax[i].plot(x_data, y_data, linewidth=0.5, color=\"black\")\n",
    "    ax[i].fill_between(x_data, ci_l, ci_h, alpha=0.5)\n",
    "    ax[i].set_title(f\"Peak Detection {i+1}\")\n",
    "    if i == 2:\n",
    "        ax[i].set_xscale('log')\n",
    "        ax[i].set_yscale('log')\n",
    "ax[0].set_xlabel('Percentile')\n",
    "ax[1].set_xlabel('Percentile')\n",
    "ax[2].set_xlabel('Probability')\n",
    "ax[3].set_xlabel('Percentile')\n",
    "fig.text(-0.02, 0.5, \"Mean of Peak Count\", va='center', rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes for me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Confidence intervalleri hesaplarken normal deÄil fisk daÄÄ±ldÄ±ÄÄ±nÄ± varsayalÄ±m...\n",
    "#plt.hist(np.nanmean(arr, axis=1), bins=256);\n",
    "#stats.fisk.interval(1,1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of tt and s, peak'leri iÃ§in, \n",
    "#Â how much they correlate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bu ilk elbow finding'de neden \"flat'Ä± seÃ§tin amk\", belki hanning 25 olunca daha az olacak??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posizyonlar ne oranda correle oluyor: tt_stalling vs monosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rpkm vs length for experiment sixtymers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update parameteres in main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ne kadar base, ssig ve dsig var"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
