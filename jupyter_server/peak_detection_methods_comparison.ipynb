{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficiency of Peak Detection Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raf_pc/miniconda3/envs/kemals/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3343: DtypeWarning: Columns (9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[04/05/2021 13:33:36 CEST]\u001b[0m Gene information dictionary is found in path: /home/raf_pc/Kemal/Temp/human/gene_info_database.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyensembl.sequence_data:Loaded sequence dictionary from /home/raf_pc/Kemal/Temp/human/Homo_sapiens.GRCh38.cdna.all.fa.pickle\n",
      "INFO:pyensembl.sequence_data:Loaded sequence dictionary from /home/raf_pc/Kemal/Temp/human/Homo_sapiens.GRCh38.pep.all.fa.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[04/05/2021 13:34:29 CEST]\u001b[0m ProteinGenome found in path: /home/raf_pc/Kemal/Temp/human/protein_genome_instance.joblib\n",
      "\u001b[92m[04/05/2021 13:34:49 CEST]\u001b[0m RiboSeq assignment for sixtymers_background found in path: /home/raf_pc/Kemal/Temp/human/riboseq_sixtymers_background.joblib\n",
      "\u001b[92m[04/05/2021 13:34:56 CEST]\u001b[0m RiboSeq assignment for sixtymers_experiment found in path: /home/raf_pc/Kemal/Temp/human/riboseq_sixtymers_experiment.joblib\n"
     ]
    }
   ],
   "source": [
    "temp_repo_dir = \"/home/raf_pc/Kemal/Temp/human\"\n",
    "data_repo_dir = \"/home/raf_pc/Kemal/Data/sam_bukau\"\n",
    "script_path_infrastructure = \"/home/raf_pc/Kemal/RiboSeqAnalysis/infrastructure\"\n",
    "import sys\n",
    "sys.path.insert(0, '/home/raf_pc/Kemal/RiboSeqAnalysis')\n",
    "from infrastructure.main import *\n",
    "\n",
    "spt = [os.path.join(data_repo_dir, i) for i in [\"Sixtymers_TT1.sam\", \"Sixtymers_TT2.sam\"]]\n",
    "sps = [os.path.join(data_repo_dir, i) for i in [\"Sixtymers_Rep1.sam\", \"Sixtymers_Rep2.sam\", \"Sixtymers_NoPK.sam\"]]\n",
    "\n",
    "erb_serb = [os.path.join(data_repo_dir, f\"SeRP/EBP1/Rep{i+1}/IP/IP{i+1}.sam\") for i in range(2)]\n",
    "erb_total = [os.path.join(data_repo_dir, f\"SeRP/EBP1/Rep{i+1}/Total/Total{i+1}.sam\") for i in range(2)]\n",
    "nac_serb = [os.path.join(data_repo_dir, f\"SeRP/NAC/Rep{i+1}/IP/IP{i+1}.sam\") for i in range(2)]\n",
    "nac_total = [os.path.join(data_repo_dir, f\"SeRP/NAC/Rep{i+1}/Total/Total{i+1}.sam\") for i in range(2)]\n",
    "\n",
    "coco_d = [os.path.join(data_repo_dir, i) for i in [\"Coco_Dis1.sam\", \"Coco_Dis2.sam\"]]\n",
    "coco_m = [os.path.join(data_repo_dir, i) for i in [\"Coco_Mono1.sam\", \"Coco_Mono2.sam\"]]\n",
    "\n",
    "exclude_genes = [\"ENSG00000160789\"]\n",
    "\n",
    "I = Infrastructre(temp_repo_dir,\n",
    "                  exclude_genes=exclude_genes,\n",
    "                  ensembl_release=102,\n",
    "                  organism=\"homo_sapiens\",\n",
    "                  #include_gene3d=True,\n",
    "                  verbose=True)\n",
    "I.riboseq_sixtymers = RiboSeqSixtymers(I.temp_repo_dir, spt, sps, \"sixtymers\",\n",
    "                                        riboseq_assign_to=\"best_transcript\", riboseq_assign_at=\"auto\",\n",
    "                                        protein_genome_instance=I.protein_genome,\n",
    "                                        gene_info_dictionary=I.gene_info,\n",
    "                                        exclude_genes=I.exclude_genes, verbose=I.verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def cleartarget(dir_path):\n",
    "    \"\"\"\n",
    "    Delete everything in the output folder\n",
    "    :param dir_path: Path of directory to delete\n",
    "    :return: None. Creates new one with the same name\n",
    "    \"\"\"\n",
    "    try:\n",
    "        shutil.rmtree(dir_path)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    os.mkdir(dir_path)\n",
    "figure_dir = os.path.join(temp_repo_dir, \"jupyter_figures_peak_detection_methods_comparison\")\n",
    "cleartarget(figure_dir)\n",
    "os.chdir(figure_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amino Acid Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |█████████-----------| 46.1% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raf_pc/Kemal/RiboSeqAnalysis/infrastructure/main.py:1521: RuntimeWarning: invalid value encountered in greater\n",
      "  normalized_peak_count = np.sum(land > 0)  # to test whether normalized peak count > 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |████████████████████| 100.0% \n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from copy import deepcopy\n",
    "\n",
    "window_len = 181\n",
    "window_flank = int(np.floor(window_len / 2))\n",
    "percentiles = (60, 70, 80, 85, 90, 92.5, 95, 97.5, 99)\n",
    "probabilities = (0.120, 0.080, 0.050, 0.025, 0.0175, 0.010, 0.004, 0.0025, 0.001)\n",
    "assert window_len % 2 == 1 and window_len >= 3\n",
    "assert len(percentiles) == len(probabilities)\n",
    "\n",
    "# Methods\n",
    "inecik1 = partial(I.riboseq_sixtymers.stalling_peaks_inecik_1, window=\"hanning\", window_len=25, \n",
    "                  min_rpkm_sixtymers=-1, min_rpkm_background=1)\n",
    "inecik2 = partial(I.riboseq_sixtymers.stalling_peaks_inecik_2, window=\"hanning\", window_len=25, wlen=300, \n",
    "                  min_rpkm_sixtymers=-1, min_rpkm_background=1)\n",
    "inecik3 = partial(I.riboseq_sixtymers.stalling_peaks_inecik_3, window=\"hanning\", window_len=25, wlen=300, \n",
    "                  min_rpkm_sixtymers=-1, min_rpkm_background=1)\n",
    "inecik4 = partial(I.riboseq_sixtymers.stalling_peaks_inecik_4, window=\"hanning\", window_len=25, wlen=300, \n",
    "                  min_rpkm_sixtymers=-1, min_rpkm_background=1)\n",
    "arpat = partial(I.riboseq_sixtymers.stalling_peaks_arpat, mmc_threshold=1, normalized_peak_count_thr=5, get_top=5)\n",
    "\n",
    "save_metadata_path = os.path.join(temp_repo_dir, \"jupyter_method_comparison_protein_sequences_params_percentile.joblib\")\n",
    "try:  # Because it takes very long, as written very inefficiently.\n",
    "    W = joblib.load(save_metadata_path)\n",
    "except FileNotFoundError:\n",
    "\n",
    "    ci = [[] for _ in range(len(percentiles))]\n",
    "    windows = [deepcopy(ci), deepcopy(ci), deepcopy(ci), deepcopy(ci), [], []]  # inecik1, inecik2, inecik3, inecik4, arpat, monte_carlo\n",
    "\n",
    "    for ind, gene_id in enumerate(I.gene_list):\n",
    "        progress_bar(ind, len(I.gene_list) - 1, verbose=True)\n",
    "        best_transcript = I.gene_info[gene_id].transcripts.iloc[0][0]  # At least 1 transcript exists\n",
    "        protein_sequence = I.protein_genome.db[best_transcript][1]\n",
    "        length_protein = len(protein_sequence)\n",
    "        assert \".\" not in protein_sequence\n",
    "        protein_sequence = \".\" * window_flank + protein_sequence + \".\" * window_flank\n",
    "        # My methods\n",
    "        for param1 in range(len(percentiles)):\n",
    "            peaks1 = (np.floor(inecik1(gene_id, percentile=percentiles[param1]) / 3) + window_flank).astype(int)\n",
    "            peaks2 = (np.floor(inecik2(gene_id, percentile=percentiles[param1]) / 3) + window_flank).astype(int)\n",
    "            peaks3 = (np.floor(inecik3(gene_id, probability=probabilities[param1]) / 3) + window_flank).astype(int)\n",
    "            peaks4 = (np.floor(inecik4(gene_id, percentile=percentiles[param1]) / 3) + window_flank).astype(int)\n",
    "            for inecik_method, peaks in zip(range(4), [peaks1, peaks2, peaks3, peaks4]):\n",
    "                for peak in peaks:\n",
    "                    windows[inecik_method][param1].append(protein_sequence[peak - window_flank: peak + window_flank + 1])\n",
    "        # Arpat\n",
    "        peaks5 = (np.floor(arpat(gene_id) / 3) + window_flank).astype(int)\n",
    "        for peak in peaks5:\n",
    "            windows[4].append(protein_sequence[peak - window_flank: peak + window_flank + 1])\n",
    "        # Monte Carlo\n",
    "        peaks_mc = (np.sort(np.random.choice(length_protein, 10)) + window_flank).astype(int)\n",
    "        for peak in peaks_mc:\n",
    "            windows[5].append(protein_sequence[peak - window_flank: peak + window_flank + 1])        \n",
    "\n",
    "    ci = [None for _ in range(len(percentiles))]\n",
    "    W = [deepcopy(ci), deepcopy(ci), deepcopy(ci), deepcopy(ci), None, None]  # inecik1, inecik2, inecik3, inecik4, arpat, monte_carlo\n",
    "\n",
    "    for inecik_method in range(4):\n",
    "        for param1 in range(len(percentiles)):\n",
    "            W_temp = np.chararray((len(windows[inecik_method][param1]), window_len), itemsize=1)\n",
    "            W_temp[:] = \".\"\n",
    "            for ind, peak_window in enumerate(windows[inecik_method][param1]):\n",
    "                W_temp[ind] = list(peak_window)\n",
    "            W[inecik_method][param1] = W_temp\n",
    "    for other_method in range(4, 6):\n",
    "        W_temp = np.chararray((len(windows[other_method]), window_len), itemsize=1)\n",
    "        W_temp[:] = \".\"\n",
    "        for ind, peak_window in enumerate(windows[other_method]):\n",
    "            W_temp[ind] = list(peak_window)\n",
    "        W[other_method] = W_temp\n",
    "\n",
    "    del windows\n",
    "    joblib.dump(W, save_metadata_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "\n",
    "# Inecik Methods\n",
    "charges = list()\n",
    "for k in range(4):\n",
    "    charges_method = list()\n",
    "    for i in range(len(percentiles)):\n",
    "        charges_temp = list()\n",
    "        W_temp = W[k][i].T\n",
    "        for j in range(window_len):\n",
    "            aminoacids_vertical = \"\".join(W_temp[j].decode()).replace(\".\", \"\")\n",
    "            pa = ProteinAnalysis(aminoacids_vertical)\n",
    "            average_charge = pa.charge_at_pH(7) / len(aminoacids_vertical)\n",
    "            charges_temp.append(average_charge)\n",
    "        charges_method.append(charges_temp)\n",
    "    charges.append(charges_method)\n",
    "# Arpat & Monte Carlo\n",
    "for k in range(4, 6):\n",
    "    charges_temp = list()\n",
    "    W_temp = W[k].T\n",
    "    for j in range(window_len):\n",
    "        aminoacids_vertical = \"\".join(W_temp[j].decode()).replace(\".\", \"\")\n",
    "        pa = ProteinAnalysis(aminoacids_vertical)\n",
    "        average_charge = pa.charge_at_pH(7) / len(aminoacids_vertical)\n",
    "        charges_temp.append(average_charge)\n",
    "    charges.append(charges_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "x=np.arange(-window_flank, window_flank + 1)\n",
    "for i in range(len(percentiles)):\n",
    "    plt.plot(x, charges[m][i], label=percentiles[i] if m!=2 else probabilities[i])\n",
    "plt.plot(x, charges[4], label=\"Arpat\")\n",
    "plt.plot(x, charges[5], label=\"Monte Carlo\", color=\"black\")\n",
    "plt.legend(loc=\"lower right\", ncol=2)\n",
    "plt.title(f\"Inecik Peak Detection {m+1}\", y=1.05, fontweight=\"bold\")\n",
    "plt.xlabel(\"Relative Position to Stalling\")\n",
    "plt.ylabel(\"Charge at pH 7\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Charge_window.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def objective_function(x1, x2, method):\n",
    "    diff = np.array(x1) - np.array(x2) # calculate difference\n",
    "    posPart = np.maximum(diff, 0) # only keep positive part, set other values to zero\n",
    "    negPart = -np.minimum(diff, 0) # only keep negative part, set other values to zero    \n",
    "    posAreaRatio = np.trapz(posPart) / np.sum(diff > 0)\n",
    "    negAreaRatio = np.trapz(negPart) / np.sum(diff < 0)\n",
    "    if method == \"Total\":\n",
    "        return posAreaRatio + negAreaRatio\n",
    "    elif method == \"Positive Only\":\n",
    "        return posAreaRatio\n",
    "    elif method == \"Negative Only\":\n",
    "        return negAreaRatio\n",
    "\n",
    "for method in [\"Total\", \"Positive Only\", \"Negative Only\"]:\n",
    "    of = partial(objective_function, method=method)\n",
    "    fig = plt.figure(figsize=(6, 5))\n",
    "    for m in range(4):\n",
    "        lengths = [len(W[m][i]) for i in range(len(percentiles))]\n",
    "        score = [of(charges[m][k], np.array(charges[5])) for k in range(len(percentiles))]\n",
    "        plt.plot(lengths, score, marker=\"x\", label=f\"Inecik {m+1}\")\n",
    "    arpat_score = of(charges[4], charges[5])\n",
    "    arpat_length = len(W[4])\n",
    "    plt.scatter(arpat_length, arpat_score, edgecolors=\"None\", label=\"Arpat's\", color=\"black\")\n",
    "    plt.title(f\"Unit Area for {method}\", y=1.05, fontweight=\"bold\")\n",
    "    plt.xlabel(\"Total Peak Count Captured\")\n",
    "    plt.ylabel(\"Charge Difference\")\n",
    "    plt.gca().set_xticklabels(['{:,.0f}'.format(x) + 'k' for x in plt.gca().get_xticks()/1000])\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"Unit_Area_for_{method}.pdf\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The grand average of hydropathy (GRAVY) value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "\n",
    "# Inecik Methods\n",
    "gravy_scores = list()\n",
    "for k in range(4):\n",
    "    gravy_method = list()\n",
    "    for i in range(len(percentiles)):\n",
    "        gravy_temp = list()\n",
    "        W_temp = W[k][i].T\n",
    "        for j in range(window_len):\n",
    "            aminoacids_vertical = \"\".join(W_temp[j].decode()).replace(\".\", \"\").replace(\"X\", \"\").replace(\"U\", \"\")\n",
    "            pa = ProteinAnalysis(aminoacids_vertical)\n",
    "            average_gravy = pa.gravy()\n",
    "            gravy_temp.append(average_gravy)\n",
    "        gravy_method.append(gravy_temp)\n",
    "    gravy_scores.append(gravy_method)\n",
    "# Arpat & Monte Carlo\n",
    "for k in range(4, 6):\n",
    "    gravy_temp = list()\n",
    "    W_temp = W[k].T\n",
    "    for j in range(window_len):\n",
    "        aminoacids_vertical = \"\".join(W_temp[j].decode()).replace(\".\", \"\").replace(\"X\", \"\").replace(\"U\", \"\")\n",
    "        pa = ProteinAnalysis(aminoacids_vertical)\n",
    "        average_gravy = pa.gravy()\n",
    "        gravy_temp.append(average_gravy)\n",
    "    gravy_scores.append(gravy_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "x=np.arange(-window_flank, window_flank + 1)\n",
    "for i in range(len(percentiles)):\n",
    "    plt.plot(x, gravy_scores[m][i], label=percentiles[i] if m!=2 else probabilities[i])\n",
    "plt.plot(x, gravy_scores[4], label=\"Arpat\")\n",
    "plt.plot(x, gravy_scores[5], label=\"Monte Carlo\", color=\"black\")\n",
    "plt.legend(loc=\"lower right\", ncol=2)\n",
    "plt.title(f\"Inecik Peak Detection {m+1}\", y=1.05, fontweight=\"bold\")\n",
    "plt.xlabel(\"Relative Position to Stalling\")\n",
    "plt.ylabel(\"Gravy Score\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Gravy_window.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Molecular Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "\n",
    "# Inecik Methods\n",
    "molwei = list()\n",
    "for k in range(4):\n",
    "    molwei_method = list()\n",
    "    for i in range(len(percentiles)):\n",
    "        molwei_temp = list()\n",
    "        W_temp = W[k][i].T\n",
    "        for j in range(window_len):\n",
    "            aminoacids_vertical = \"\".join(W_temp[j].decode()).replace(\".\", \"\").replace(\"X\", \"\").replace(\"U\", \"\")\n",
    "            pa = ProteinAnalysis(aminoacids_vertical)\n",
    "            average_mw = pa.molecular_weight() / len(aminoacids_vertical)\n",
    "            molwei_temp.append(average_mw)\n",
    "        molwei_method.append(molwei_temp)\n",
    "    molwei.append(molwei_method)\n",
    "# Arpat & Monte Carlo\n",
    "for k in range(4, 6):\n",
    "    molwei_temp = list()\n",
    "    W_temp = W[k].T\n",
    "    for j in range(window_len):\n",
    "        aminoacids_vertical = \"\".join(W_temp[j].decode()).replace(\".\", \"\").replace(\"X\", \"\").replace(\"U\", \"\")\n",
    "        pa = ProteinAnalysis(aminoacids_vertical)\n",
    "        average_mw = pa.molecular_weight() / len(aminoacids_vertical)\n",
    "        molwei_temp.append(average_mw)\n",
    "    molwei.append(molwei_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "x=np.arange(-window_flank, window_flank + 1)\n",
    "for i in range(len(percentiles)):\n",
    "    plt.plot(x, molwei[m][i], label=percentiles[i] if m!=2 else probabilities[i])\n",
    "plt.plot(x, molwei[4], label=\"Arpat\")\n",
    "plt.plot(x, molwei[5], label=\"Monte Carlo\", color=\"black\")\n",
    "plt.legend(loc=\"lower right\", ncol=2)\n",
    "plt.title(f\"Inecik Peak Detection {m+1}\", y=1.05, fontweight=\"bold\")\n",
    "plt.xlabel(\"Relative Position to Stalling\")\n",
    "plt.ylabel(\"Molecular Weight\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Molecular_Weight_window.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secondary Structure Fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "\n",
    "# Inecik Methods\n",
    "ssf = list()\n",
    "for k in range(4):\n",
    "    ssf_method = list()\n",
    "    for i in range(len(percentiles)):\n",
    "        ssf_temp = list()\n",
    "        W_temp = W[k][i].T\n",
    "        for j in range(window_len):\n",
    "            aminoacids_vertical = \"\".join(W_temp[j].decode()).replace(\".\", \"\").replace(\"X\", \"\").replace(\"U\", \"\")\n",
    "            pa = ProteinAnalysis(aminoacids_vertical)\n",
    "            average_ssf = pa.secondary_structure_fraction()\n",
    "            ssf_temp.append(average_ssf)\n",
    "        ssf_method.append(ssf_temp)\n",
    "    ssf.append(ssf_method)\n",
    "# Arpat & Monte Carlo\n",
    "for k in range(4, 6):\n",
    "    ssf_temp = list()\n",
    "    W_temp = W[k].T\n",
    "    for j in range(window_len):\n",
    "        aminoacids_vertical = \"\".join(W_temp[j].decode()).replace(\".\", \"\").replace(\"X\", \"\").replace(\"U\", \"\")\n",
    "        pa = ProteinAnalysis(aminoacids_vertical)\n",
    "        average_ssf = pa.secondary_structure_fraction()\n",
    "        ssf_temp.append(average_ssf)\n",
    "    ssf.append(ssf_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2\n",
    "aacids = [[\"V\", \"I\", \"Y\", \"F\", \"W\", \"L\"], [\"N\", \"P\", \"G\", \"S\"], [\"E\", \"M\", \"A\", \"L\"]]\n",
    "for ind, stracture, aacid in zip(range(3), [\"Helix\", \"Turn\", \"Sheet\"], aacids):\n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "    x=np.arange(-window_flank, window_flank + 1)\n",
    "    for i in range(len(percentiles)):\n",
    "        plt.plot(x, np.array(ssf[m][i]).T[ind], label=percentiles[i] if m!=2 else probabilities[i])\n",
    "    plt.plot(x, np.array(ssf[4]).T[ind], label=\"Arpat\")\n",
    "    plt.plot(x, np.array(ssf[5]).T[ind], label=\"Monte Carlo\", color=\"black\")\n",
    "    plt.legend(loc=\"lower right\", ncol=2)\n",
    "    plt.title(f\"Inecik Peak Detection {m+1}: {stracture} ({', '.join(aacid)})\", y=1.05, fontweight=\"bold\")\n",
    "    plt.xlabel(\"Relative Position to Stalling\")\n",
    "    plt.ylabel(f\"Fraction of Aa. in {stracture}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"secondary_window{stracture}.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amino Acid residues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "\n",
    "def aa_probs(mm=\"P\"):\n",
    "    # Inecik Methods\n",
    "    proline = list()\n",
    "    for k in range(4):\n",
    "        proline_method = list()\n",
    "        for i in range(len(percentiles)):\n",
    "            proline_temp = list()\n",
    "            W_temp = W[k][i].T\n",
    "            for j in range(window_len):    \n",
    "                aminoacids_vertical = \"\".join(W_temp[j].decode()).replace(\".\", \"\").replace(\"X\", \"\").replace(\"U\", \"\")\n",
    "                pa = ProteinAnalysis(aminoacids_vertical)\n",
    "                average_proline = pa.get_amino_acids_percent()[mm]\n",
    "                proline_temp.append(average_proline)\n",
    "            proline_method.append(proline_temp)\n",
    "        proline.append(proline_method)\n",
    "    # Arpat & Monte Carlo\n",
    "    for k in range(4, 6):\n",
    "        proline_temp = list()\n",
    "        W_temp = W[k].T\n",
    "        for j in range(window_len):\n",
    "            aminoacids_vertical = \"\".join(W_temp[j].decode()).replace(\".\", \"\").replace(\"X\", \"\").replace(\"U\", \"\")\n",
    "            pa = ProteinAnalysis(aminoacids_vertical)\n",
    "            average_proline = pa.get_amino_acids_percent()[mm]\n",
    "            proline_temp.append(average_proline)\n",
    "        proline.append(proline_temp)\n",
    "    return proline\n",
    "    \n",
    "aa = ['C', 'D', 'S', 'Q', 'K', 'I', 'P', 'T', 'F', 'N', 'G', 'H', 'L', 'R', 'W', 'A', 'V', 'E', 'Y', 'M']\n",
    "save_metadata_path = os.path.join(temp_repo_dir, \"jupyter_method_comparison_amino_acid_probabilities.joblib\")\n",
    "try:  # Because it takes very long, as written very inefficiently.\n",
    "    aad = joblib.load(save_metadata_path)\n",
    "except FileNotFoundError:\n",
    "    executor = multiprocessing.Pool(len(aa))\n",
    "    result = executor.map(aa_probs, aa)\n",
    "    executor.terminate()\n",
    "    executor.join()\n",
    "    aad = dict(zip(aa, result))\n",
    "    joblib.dump(aad, save_metadata_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = \"P\"\n",
    "m = 2\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "x = np.arange(-window_flank, window_flank + 1)\n",
    "for i in range(len(percentiles)):\n",
    "    plt.plot(x, aad[mm][m][i], label=percentiles[i] if m!=2 else probabilities[i])\n",
    "plt.plot(x, aad[mm][4], label=\"Arpat\")\n",
    "plt.plot(x, aad[mm][5], label=\"Monte Carlo\", color=\"black\")\n",
    "plt.legend(loc=\"lower right\", ncol=2)\n",
    "plt.title(f\"Inecik Peak Detection {m+1}: Amino acid {mm}\", y=1.05, fontweight=\"bold\")\n",
    "plt.xlabel(\"Relative Position to Stalling\")\n",
    "plt.ylabel(\"Proline Probability\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Proline_window.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More accurate objective function\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Position_weight_matrix\n",
    "def information_content(aad, inecik_method, perc):  # Relative entropy\n",
    "    ic = 0\n",
    "    for mm in aa:  \n",
    "        observed = np.array(aad[mm][inecik_method][perc])\n",
    "        expected = np.array(aad[mm][-1])\n",
    "        ic += - np.log(expected/observed) * observed\n",
    "    return ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, information_content(aad, 2, 2))\n",
    "plt.plot(x, information_content(aad, 2, 5))\n",
    "plt.title(\"Information Content (Relative Entropy)\", y=1.05, fontweight=\"bold\")\n",
    "plt.savefig(\"information_content.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logomaker\n",
    "mmaa = list()\n",
    "method_number = 2\n",
    "ic = information_content(aad, method_number, percentiles.index(90))\n",
    "for mm in aa:\n",
    "    observed = np.array(aad[mm][method_number][percentiles.index(90)])\n",
    "    expected = np.array(aad[mm][5])\n",
    "    position_weight_matrix = ic * np.log(observed/expected)\n",
    "    mmaa.append(position_weight_matrix)\n",
    "    # http://www.bioinformatics.org/blogo/help.htm\n",
    "    # https://en.wikipedia.org/wiki/Sequence_logo\n",
    "    # https://en.wikipedia.org/wiki/Position_weight_matrix\n",
    "ww_df = pd.DataFrame.from_dict(dict(zip(aa, mmaa)))\n",
    "ww_df.index = np.arange(-window_flank, window_flank + 1)\n",
    "\n",
    "# Plot\n",
    "ww_df=ww_df.loc[-25: 25]\n",
    "fig, ax = plt.subplots(1,1,figsize=[12,5])\n",
    "ss_logo = logomaker.Logo(ww_df, flip_below=False, color_scheme='chemistry', ax=ax)\n",
    "ss_logo.ax.set_ylabel(r\"Log-Likelihood $\\times$ Relative Entropy\")\n",
    "ss_logo.ax.set_xlabel(\"Relative Position\")\n",
    "ss_logo.ax.set_title(\"Stalling Site Logo\", y=1.05, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Logo_info_2ll.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmaa = list()\n",
    "for mm in aa:\n",
    "    observed = np.array(aad[mm][method_number][percentiles.index(90)])\n",
    "    expected = np.array(aad[mm][5])\n",
    "    position_weight_matrix = np.log(observed/expected)\n",
    "    mmaa.append(position_weight_matrix)\n",
    "    # http://www.bioinformatics.org/blogo/help.htm\n",
    "    # https://en.wikipedia.org/wiki/Sequence_logo\n",
    "    # https://en.wikipedia.org/wiki/Position_weight_matrix\n",
    "ww_df = pd.DataFrame.from_dict(dict(zip(aa, mmaa)))\n",
    "ww_df.index = np.arange(-window_flank, window_flank + 1)\n",
    "\n",
    "# Plot\n",
    "ww_df=ww_df.loc[-25: 25]\n",
    "fig, ax = plt.subplots(1,1,figsize=[12,5])\n",
    "ss_logo = logomaker.Logo(ww_df, flip_below=False, color_scheme='chemistry', ax=ax)\n",
    "ss_logo.ax.set_ylabel(r\"Position Weighted Log-Likelihood\")\n",
    "ss_logo.ax.set_xlabel(\"Relative Position\")\n",
    "ss_logo.ax.set_title(\"Stalling Site Logo\", y=1.05, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Logo_2ll.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method comparison with relative entropy as objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_ent = np.zeros((4,len(percentiles)))\n",
    "for i1 in range(4):\n",
    "    for i2 in range(len(percentiles)):\n",
    "        rel_ent[i1, i2] = np.sum(information_content(aad, i1, i2))\n",
    "\n",
    "import seaborn as sns\n",
    "heat = sns.heatmap(rel_ent, annot=True, xticklabels=percentiles)\n",
    "plt.gca().set_yticklabels(range(1,5), rotation=0)\n",
    "plt.title(\"Relative Entropy\", y=1.1, fontweight=\"bold\")\n",
    "plt.xlabel(\"Percentile\")\n",
    "plt.ylabel(\"Inecik Peak Detection\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"heatmap_method_comparison.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Science 185:862-864(1974).\n",
    "# https://web.expasy.org/protscale/pscale/PolarityGrantham.html\n",
    "polarity_dict = {\"A\":  8.100, \"R\": 10.500, \"N\": 11.600, \"D\": 13.000, \"C\":  5.500, \n",
    "                 \"Q\": 10.500, \"E\": 12.300, \"G\":  9.000, \"H\": 10.400, \"I\":  5.200, \n",
    "                 \"L\":  4.900, \"K\": 11.300, \"M\":  5.700, \"F\":  5.200, \"P\":  8.000, \n",
    "                 \"S\":  9.200, \"T\":  8.600, \"W\":  5.400, \"Y\":  6.200, \"V\":  5.900}\n",
    "aa = ['C', 'D', 'S', 'Q', 'K', 'I', 'P', 'T', 'F', 'N', 'G', 'H', 'L', 'R', 'W', 'A', 'V', 'E', 'Y', 'M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inecik Methods\n",
    "polarity = list()\n",
    "for k in range(4):\n",
    "    polarity_method = list()\n",
    "    for i in range(len(percentiles)):\n",
    "        polarity_temp = np.sum([np.array(aad[mm][k][i]) * polarity_dict[mm] for mm in aa], axis=0)\n",
    "        polarity_method.append(polarity_temp)\n",
    "    polarity.append(polarity_method)\n",
    "# Arpat & Monte Carlo\n",
    "for k in range(4, 6):\n",
    "    polarity_temp = np.sum([np.array(aad[mm][k]) * polarity_dict[mm] for mm in aa], axis=0)\n",
    "    polarity.append(polarity_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "x=np.arange(-window_flank, window_flank + 1)\n",
    "for i in range(len(percentiles)):\n",
    "    plt.plot(x, polarity[m][i], label=percentiles[i] if m!=2 else probabilities[i])\n",
    "plt.plot(x, polarity[4], label=\"Arpat\")\n",
    "plt.plot(x, polarity[5], label=\"Monte Carlo\", color=\"black\")\n",
    "plt.legend(loc=\"lower right\", ncol=2)\n",
    "plt.title(f\"Inecik Peak Detection {m+1}\", y=1.05, fontweight=\"bold\")\n",
    "plt.xlabel(\"Relative Position to Stalling\")\n",
    "plt.ylabel(\"Polarity\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"polarity_window.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flexibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Science 185:862-864(1974).\n",
    "# https://web.expasy.org/protscale/pscale/PolarityGrantham.html\n",
    "flexibility_dict = {\"A\":  0.360, \"R\":  0.530, \"N\":  0.460, \"D\":  0.510, \"C\":  0.350, \n",
    "                 \"Q\":  0.490, \"E\":  0.500, \"G\":  0.540, \"H\":  0.320, \"I\":  0.460, \n",
    "                 \"L\":  0.370, \"K\":  0.470, \"M\":  0.300, \"F\":  0.310, \"P\":  0.510, \n",
    "                 \"S\":  0.510, \"T\":  0.440, \"W\":  0.310, \"Y\":  0.420, \"V\":  0.390}\n",
    "aa = ['C', 'D', 'S', 'Q', 'K', 'I', 'P', 'T', 'F', 'N', 'G', 'H', 'L', 'R', 'W', 'A', 'V', 'E', 'Y', 'M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inecik Methods\n",
    "flexibility = list()\n",
    "for k in range(4):\n",
    "    flexibility_method = list()\n",
    "    for i in range(len(percentiles)):\n",
    "        flexibility_temp = np.sum([np.array(aad[mm][k][i]) * flexibility_dict[mm] for mm in aa], axis=0)\n",
    "        flexibility_method.append(flexibility_temp)\n",
    "    flexibility.append(flexibility_method)\n",
    "# Arpat & Monte Carlo\n",
    "for k in range(4, 6):\n",
    "    flexibility_temp = np.sum([np.array(aad[mm][k]) * flexibility_dict[mm] for mm in aa], axis=0)\n",
    "    flexibility.append(flexibility_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "x=np.arange(-window_flank, window_flank + 1)\n",
    "for i in range(len(percentiles)):\n",
    "    plt.plot(x, flexibility[m][i], label=percentiles[i] if m!=2 else probabilities[i])\n",
    "plt.plot(x, flexibility[4], label=\"Arpat\")\n",
    "plt.plot(x, flexibility[5], label=\"Monte Carlo\", color=\"black\")\n",
    "plt.legend(loc=\"lower right\", ncol=2)\n",
    "plt.title(f\"Inecik Peak Detection {m+1}\", y=1.05, fontweight=\"bold\")\n",
    "plt.xlabel(\"Relative Position to Stalling\")\n",
    "plt.ylabel(\"Flexibility\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Flexibility_window.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_content_arpat(aad):  # Relative entropy\n",
    "    ic = 0\n",
    "    for mm in aa:  \n",
    "        observed = np.array(aad[mm][-2])\n",
    "        expected = np.array(aad[mm][-1])\n",
    "        ic += - np.log(expected/observed) * observed\n",
    "    return ic\n",
    "\n",
    "fig = plt.figure(figsize=(6, 5))\n",
    "for m in range(4):\n",
    "    lengths = [len(W[m][i]) for i in range(len(percentiles))]\n",
    "    score = [np.sum(information_content(aad, m, k)) for k in range(len(percentiles))]\n",
    "    plt.plot(lengths, score, marker=\"x\", label=f\"Inecik {m+1}\")\n",
    "arpat_score = np.sum(information_content_arpat(aad))\n",
    "arpat_length = len(W[4])\n",
    "plt.scatter(arpat_length, arpat_score, edgecolors=\"None\", label=\"Arpat's\", color=\"black\")\n",
    "plt.title(f\"Information Content for Peak Detection Methods\", y=1.05, fontweight=\"bold\")\n",
    "plt.xlabel(\"Total Peak Count Captured\")\n",
    "plt.ylabel(\"Relative Entropy\")\n",
    "plt.gca().set_xticklabels(['{:,.0f}'.format(x) + 'k' for x in plt.gca().get_xticks()/1000])\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"best_percentile_curves.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scanning wlen and percentile for Inecik 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from copy import deepcopy\n",
    "\n",
    "window_len = 181\n",
    "window_flank = int(np.floor(window_len / 2))\n",
    "percentiles_wlen = (70, 80, 85, 90, 92.5, 95, 97.5, 99)\n",
    "wlens = (10, 15, 20, 30, 50, 150, 500, 1000)\n",
    "assert window_len % 2 == 1 and window_len >= 3\n",
    "\n",
    "# Methods\n",
    "inecik2 = partial(I.riboseq_sixtymers.stalling_peaks_inecik_2, window=\"hanning\", window_len=23, min_rpkm_sixtymers=-1, min_rpkm_translatome=1)\n",
    "\n",
    "save_metadata_path = os.path.join(temp_repo_dir, \"jupyter_method_comparison_protein_sequences_params_wlen_percentile_inecik2.joblib\")\n",
    "try:  # Because it takes very long, as written very inefficiently.\n",
    "    W_wlen = joblib.load(save_metadata_path)\n",
    "except FileNotFoundError:\n",
    "    gene_list_calc = I.gene_list\n",
    "    counter = 0\n",
    "    total_iteration = (len(wlens)) * (len(gene_list_calc))\n",
    "    windows = [[[] for _ in range(len(percentiles_wlen))] for _ in range(len(wlens))] + [[]]   # inecik1, monte_carlo\n",
    "    for ind1, wlen in enumerate(wlens):\n",
    "        for ind3, gene_id in enumerate(gene_list_calc):\n",
    "            counter += 1\n",
    "            if counter % 1000 == 1:\n",
    "                progress_bar(counter, total_iteration, verbose=True, suffix=f\"    wlen {ind1 + 1}: {wlen}\")\n",
    "            best_transcript = I.gene_info[gene_id].transcripts.iloc[0][0]  # At least 1 transcript exists\n",
    "            protein_sequence = I.protein_genome.db[best_transcript][1]\n",
    "            length_protein = len(protein_sequence)\n",
    "            assert \".\" not in protein_sequence\n",
    "            protein_sequence = \".\" * window_flank + protein_sequence + \".\" * window_flank\n",
    "            # My method\n",
    "            for ind2, perc in enumerate(percentiles_wlen):\n",
    "                peaks2 = (np.floor(inecik2(gene_id, percentile=perc, wlen=wlen) / 3) + window_flank).astype(int)\n",
    "                for peak in peaks2:\n",
    "                    windows[ind1][ind2].append(protein_sequence[peak - window_flank: peak + window_flank + 1])\n",
    "            if ind1 == 0:\n",
    "                # Monte Carlo\n",
    "                peaks_mc = (np.sort(np.random.choice(length_protein, 10)) + window_flank).astype(int)\n",
    "                for peak in peaks_mc:\n",
    "                    windows[-1].append(protein_sequence[peak - window_flank: peak + window_flank + 1])\n",
    "    # Convert to chararray\n",
    "    W_wlen = [[None for _ in range(len(percentiles_wlen))] for _ in range(len(wlens))] + [None]\n",
    "    for wle in range(len(wlens)):\n",
    "        for per in range(len(percentiles_wlen)):\n",
    "            W_temp = np.chararray((len(windows[wle][per]), window_len), itemsize=1)\n",
    "            W_temp[:] = \".\"\n",
    "            for ind, peak_window in enumerate(windows[wle][per]):\n",
    "                W_temp[ind] = list(peak_window)\n",
    "            W_wlen[wle][per] = W_temp\n",
    "    # Monte Carlo\n",
    "    W_temp = np.chararray((len(windows[-1]), window_len), itemsize=1)\n",
    "    W_temp[:] = \".\"\n",
    "    for ind, peak_window in enumerate(windows[-1]):\n",
    "        W_temp[ind] = list(peak_window)\n",
    "    W_wlen[-1] = W_temp\n",
    "    # Return\n",
    "    del windows\n",
    "    joblib.dump(W_wlen, save_metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "\n",
    "def aa_probs_wlen(mm=\"P\"):\n",
    "    # Inecik Methods\n",
    "    proline = list()\n",
    "    for k in range(len(wlens)):\n",
    "        proline_method = list()\n",
    "        for i in range(len(percentiles_wlen)):\n",
    "            proline_temp = list()\n",
    "            W_temp = W_wlen[k][i].T\n",
    "            for j in range(window_len):    \n",
    "                aminoacids_vertical = \"\".join(W_temp[j].decode()).replace(\".\", \"\").replace(\"X\", \"\").replace(\"U\", \"\")\n",
    "                pa = ProteinAnalysis(aminoacids_vertical)\n",
    "                average_proline = pa.get_amino_acids_percent()[mm]\n",
    "                proline_temp.append(average_proline)\n",
    "            proline_method.append(proline_temp)\n",
    "        proline.append(proline_method)\n",
    "    # Monte Carlo\n",
    "    proline_temp = list()\n",
    "    W_temp = W_wlen[-1].T\n",
    "    for j in range(window_len):\n",
    "        aminoacids_vertical = \"\".join(W_temp[j].decode()).replace(\".\", \"\").replace(\"X\", \"\").replace(\"U\", \"\")\n",
    "        pa = ProteinAnalysis(aminoacids_vertical)\n",
    "        average_proline = pa.get_amino_acids_percent()[mm]\n",
    "        proline_temp.append(average_proline)\n",
    "    proline.append(proline_temp)\n",
    "    return proline\n",
    "\n",
    "aa = ['C', 'D', 'S', 'Q', 'K', 'I', 'P', 'T', 'F', 'N', 'G', 'H', 'L', 'R', 'W', 'A', 'V', 'E', 'Y', 'M']\n",
    "save_metadata_path = os.path.join(temp_repo_dir, \"jupyter_method_comparison_amino_acid_probabilities_wlen_scan.joblib\")\n",
    "try:  # Because it takes very long, as written very inefficiently.\n",
    "    aad_wlen = joblib.load(save_metadata_path)\n",
    "except FileNotFoundError:\n",
    "    executor = multiprocessing.Pool(len(aa))\n",
    "    result = executor.map(aa_probs_wlen, aa)\n",
    "    executor.terminate()\n",
    "    executor.join()\n",
    "    aad_wlen = dict(zip(aa, result))\n",
    "    joblib.dump(aad_wlen, save_metadata_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "rel_ent = np.zeros((len(wlens),len(percentiles_wlen)))\n",
    "for i1 in range(len(wlens)):\n",
    "    for i2 in range(len(percentiles_wlen)):\n",
    "        rel_ent[i1, i2] = np.sum(information_content(aad_wlen, i1, i2))\n",
    "        \n",
    "heat_wlen = sns.heatmap(rel_ent, annot=True, xticklabels=percentiles_wlen)\n",
    "plt.gca().set_yticklabels(wlens, rotation=0)\n",
    "plt.title(\"Relative Entropy\", y=1.1, fontweight=\"bold\")\n",
    "plt.xlabel(\"Percentile\")\n",
    "plt.ylabel(\"Wlen\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"percentile_wlen_scan.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analayse the regions 92.5-95 arası gibi to pinpoint important peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GERP Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
